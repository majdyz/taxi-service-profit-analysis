\documentclass{article}

\usepackage{graphicx}
\usepackage{amsmath}
\usepackage[margin=1.5in]{geometry}
\usepackage{setspace}
\usepackage{indentfirst}
\usepackage{changepage}
\usepackage{titlesec}

\onehalfspacing
\setlength\parindent{1cm}

\titleformat{\section}[block]{\bfseries}{\thesection.}{1em}{}
\titleformat{\subsection}[block]{\bfseries}{\thesubsection}{1em}{}
\titleformat{\subsubsection}[block]{\bfseries}{\thesubsubsection}{1em}{}
\titlespacing*{\subsection} {2em}{3.25ex plus 1ex minus .2ex}{1.5ex plus .2ex}
\titlespacing*{\subsubsection} {4em}{3.25ex plus 1ex minus .2ex}{1.5ex plus .2ex}

\begin{document}

\begin{titlepage}

\begin{center}
\vspace*{1cm}

\textbf{Data Mining}

\vspace{0.5cm}
Mining Data from Dataset

\vspace{1.5cm}

\textbf{Sebut Saja Zamil}

\vspace{1.5cm}

\vspace{1.5cm}

A thesis presented for the degree of\\
Medalist of IOI

\vspace{0.8cm}

Pelatnas 4\\
Tim Olimpiade Komputer Indonesia\\
Indonesia\\
10 August 2015

\end{center}
\end{titlepage}

\tableofcontents
\newpage

\section{Latar Belakang}

Informasi adalah hal yang sangat penting. Informasi memungkinkan seseorang untuk bertindak dengan lebih relevan dengan keadaan saat itu. Dengan adanya informasi, keputusan dapat diambil dengan lebih tepat sehingga memperoleh hasil yang lebih optimal. Salah satu contoh pentingnya informasi adalah dalam bidang bisnis. Agar dapat menguasai dunia bisnis, kita harus mengetahui dan menguasai fenomena-fenomena yang terjadi di pasar. Dengan memiliki data tentang hal-hal yang terjadi di pasar, mengolahnya, dan mengambil informasi yang terdapat dalam data itu, kita dapat mengetahui kejadian di pasar, memprediksi apa yang mungkin terjadi, mengetahui keberadaan anomali dalam bisnis, serta mengambil langkah yang tepat.

Dewasa ini, bentuk konkrit dari informasi yang beredar adalah data. Data beredar dalam jumlah yang sangat banyak sehingga tidak mungkin dapat dilakukan pemprosesan data-data tersebut satu persatu. Padahal, informasi yang terkandung dalam data tersebut sangatlah bermanfaat. Oleh karena itu, diperlukan metode khusus untuk mengolah data sehingga informasi-informasi yang bermanfaat tersebut dapat diperoleh.

Dalam studi ilmu komputer, terdapat bidang yang khusus mempelajari pengolahan data dalam jumlah besar, yakni data mining. Teknik-teknik dalam data mining memungkinkan pengolahan data besar secara optimal sehingga informasi-informasi yang bermanfaat dapat diperoleh dari data-data tersebut. Salah satu contoh aplikasi data mining yang akan kami bahas dalam makalah ini adalah pengolahan terhadap dataset pemesanan taksi di Portugal pada tanggal 1 Juli 2013 hingga 30 Juni 2014.

\section{Tujuan dan Manfaat}

Analisa yang kami lakukan bertujuan mencari anomali pada penggunaan layanan taksi dengan pembagian berdasarkan daerah. Anomali yang dicari adalah anomali divergensi keuntungan, yakni perbedaan drastis keuntungan pada suatu daerah dengan skala waktu per bulan. Perbedaan drastis ini dapat berupa penurunan maupun kenaikan yang drastis. Keuntungan per daerah ini dihitung dengan memperhitungkan perjalanan-perjalanan dengan daerah tersebut sebagai titik awal maupun titik tujuan perjalanan.

Manfaat yang dapat diperoleh dari analisa ini adalah identifikasi daerah yang memiliki tingkat permintaan yang berubah drastis. Dengan mengetahui daerah-daerah yang mengalami perubahan tingkat permintaan yang tinggi, dapat dilakukan analisa bisnis yang memadai untuk memaksimalkan keuntungan, misalnya menambah armada di sekitar daerah yang permintaannya menaik drastis. Analisa ini akan sangat berguna apabila dilakukan stream data baru terus menerus per bulannya, agar hasil analisa ini dapat digunakan untuk mengambil kebijakan bisnis secara lebih real time.  Analisa dari segi bisnis secara khusus tidak dibahas dalam makalah ini.

\section{Batasan}

Pada penelitian ini penulis melakukan pengamatan terhadap data-data yang memiliki \textit{daytype} A. Hal ini dilakukan karena daytype A paling umum ditemui diantara ketiga daytype tersebut, sementara setiap daytype tentu memiliki data yang sangat berbeda, sehingga tidak mungkin melakukan evaluasi yang sama terhadap ketiga daytype tersebut. Karena data dengan daytype A masih sangat banyak, algoritma yang digunakan adalah algoritma-algoritma yang memiliki kompleksitas rendah, misalnya k-means algorithm dan  isotonic regression yang memiliki kompleksitas linear terhadap banyaknya data.

\section{Metode}

\subsection{Perangkat Lunak}

\subsubsection{WEKA Visualization and Learning Library}
\begin{adjustwidth}{4em}{0pt}

\hspace{\parindent}WEKA adalah \textit{learning} dan \textit{visualization} \textit{library} yang di kembangkan menggunakan bahasa Java. \textit{Library} ini memiliki banyak implementasi pemrosesan data dan algoritma learning yang cukup beragam seperti Support Vector Machine, Artificial Neural Network, dan tentu algoritma utama yang di pakai pada project ini yaitu K-Means dan Isotonic Regression. Kelebihan library Java dibandingkan library lain adalah nature bahasa Java yang bisa di optimasi dan cukup cepat dibandingkan \textit{library} lain (dalam kasus ini adalah library python \footnote{http://benchmarksgame.alioth.debian.org/u64q/python.html}). Metode analisa pada kasus  ini membutuhkan data secara utuh (tidak melalui metode sampling) sehingga pemrosesan data dengan cepat sangat dibutuhkan pada kasus ini. Sehingga library ini merupakan pilihan yang cukup tepat.

\end{adjustwidth}

\subsubsection{ChartJS dan D3JS}
\begin{adjustwidth}{4em}{0pt}
	
\hspace{\parindent}Chart JS merupakan library dengan bahasa Javascript yang digunakan untuk melakukan visualisasi data dalam bentuk chart. Chart JS ini dipilih karena library ini merupakan library yang cukup ekstensif dan dapat digunakan untuk berbagai pemodelan data. Sedangkan D3JS merupakan library visualisasi Data Driven Document. D3JS digunakan untuk visualisasi data yang lebih kompleks seperti visualisasi heatmap. Dua library menghasilkan web-based visualization yang lebih mudah diolah dibandingkan file dalam bentuk gambar.

\end{adjustwidth}

\subsubsection{Python (Scikit-Learn \& GGplot)}
\begin{adjustwidth}{4em}{0pt}
		
\hspace{\parindent}Python pada kasus ini digunakan untuk melakukan prototyping, untuk mengevaluasi data sample yang berjumlah kecil untuk menguji model algoritma yang diberikan pada data. Python dipilih karena kemudahan implementasinya dan dapat kembangkan dengan cepat. Semua algoritma yang di  kembangkan disini diimplementasikan ulang menggunakan Java untuk data utuh.

\end{adjustwidth}

\subsection{Dataset}

\begin{adjustwidth}{2em}{0pt}

\hspace{\parindent}Dataset yang digunakan adalah data taxi service trip yang merupakan data penggunaan jasa taxi yang tercatat pada (hari Senin 01 Juli 2013 00:00:58 GMT sampai dengan Senin, 30 Juni 2014 19:39:07 GMT). Terdapat 1710670 penggunaan jasa taxi pada interval waktu tersebut, hanya 10 penggunaan yg tidak memiliki keterangan data yang lengkap.

Dataset memiliki 9 atribut, yaitu \textit{trip\_id}, \textit{call\_type}, \textit{origin\_call}, \textit{origin\_stand}, \textit{taxi\_id}, \textit{timestamp}, \textit{day\_type}, \textit{missing}, dan \textit{polyline}. Penjelasan untuk masing-masing atribut adalah sebagai berikut:

\begin{itemize}
\item{\textit{trip\_id} : ID untuk setiap trip penggunaan taxi}
\item{\textit{call\_type} : Tipe penggunaan jasa taxi (A : permintaan langsung ke pusat, B : permintaan langsung ke supir taxi, C : penggunaan jasa taxi di tengah jalan)}
\item{\textit{origin\_call} : ID nomor telepon pemesan (hanya untuk call\_type A)}
\item{\textit{origin\_stand} : ID stand taxi (hanya untuk call\_type B)}
\item{\textit{taxi\_id} : ID supir taxi}
\item{\textit{timestamp} : Unix Timestamp (dalam detik). yg menandakan waktu mulai perjalanan.}
\item{\textit{day\_type} :  Tipe hari pemesanan (A : hari kerja, B : hari libur, C : hari sebelum hari libur)}
\item{\textit{missing} : Boolean (False jika data gps utuh, True jika data gps ada yang hilang)}
\item{\textit{polyline} : Data koordinat gps (WGS84 format) perjalanan taxi selama 15 detik}
\end{itemize}

\end{adjustwidth}

\subsection{Algoritma dan Teknik}

\subsubsection{K-Means}
\begin{adjustwidth}{4em}{0pt}

\hspace{\parindent}K-means adalah salah satu metode clustering yang populer digunakan dalam penerapan data mining. K-means dibangun dari ide bahwa 2 buah data yang memiliki kemiripan akan dikelompokkan ke dalam sebuah cluster. Kemiripan diukur dari jarak Euclidean (Euclidean distance) dari 2 buah data. Dalam kasus ini, jarak Euclidean dihitung dengan cara jarak Euclidean antara centroid data perjalanan yang tercatat oleh \textit{gps} pada data.

Euclidean distance antara titik a dan b dihitung sebagai berikut:
\begin{align*}
	dist(a,b) &= \sqrt{(x_{a} - x_{b})^2 + (y_{a} - y_{b})^2}
\end{align*}

\end{adjustwidth}

\subsubsection{Davis Bouldin Index}

\begin{align*}
DB_{k} &= \frac{1}{k}\sum\limits_{i=1}^k
\max\limits_{j=1,...,k,i\neq j}\frac{diam(c_i +) + diam(c_j)}{dist(z_i,z_j)}
\end{align*}

\begin{align*}
diam(c_i) &= \sqrt{\frac{1}{n_i}\sum\limits_{x\in c_i}dist(x,z_i)^2}
\end{align*}

\begin{itemize}
	\setlength{\itemindent}{1cm}
	\item{$c_i$ adalah cluster}
	\item{diam($c_i$) adalah diameter cluster $c_i$}
	\item{n adalah banyaknya titik}
	\item{$z_i$ adalah centroid cluster $c_i$}
	\item{dist(a,b) adalah \textit{euclidean distance} antara titik a dan b}
\end{itemize}

\subsubsection{Haversine Formula}

\begin{adjustwidth}{4em}{0pt}
	
\hspace{\parindent}Haversine Formula adalah salah satu formula trigonometri yang digunakan untuk menghitung great circle distance, yakni jarak terdekat antara 2 titik pada permukaan bola dengan melalui permukaan bola tersebut. Haversine formula menghitung great circle distance dari 2 titik pada permukaan bola dengan parameter latitude dan longitude dari kedua titik tersebut.

Haversine formula didefinisikan sebagai berikut:
\begin{align*}
haversin(\frac{d}{r}) &= haversin(\phi _{2} - \phi _{1}) + cos(\phi _{1})cos(\phi _{2})haversin(\lambda _{2} - \lambda _{1})
\end{align*}
\begin{itemize}
	\setlength{\itemindent}{1cm}
	\item{d adalah \textit{great circle distance} antara tiitk 1 dan 2}
	\item{r adalah jari-jari bola}
	\item{$\phi$ adalah latitude}
	\item{$\lambda$ adalah longitude}
	\item{\textit{haversin} adalah fungsi trigonometri $haversin(\theta) = sin^2(\frac{\theta}{2}) = \frac{1-cos(\theta)}{2}$}
\end{itemize}

\end{adjustwidth}

\subsubsection{Isotonic Regression}
\begin{adjustwidth}{4em}{0pt}
	
\hspace{\parindent}Isotonic regression merupakan varian dari algoritma regresi yang memepertahankan arah trend dari perdictor regresi (fungsi regresi dipastikan monoton menaik atau menurun). Secara matematis definisi isotonic regression adalah sebagai berikut : diberikan data dengan nilai a1,a2,...,an, regresi F(x) merupakan fungsi monoton $(F(i) <= F(j) | i <= j)$  dengan nilai $\sum\limits_{i=1}^n({f(i)-a_{i}})^2$ seminimal mungkin.

\end{adjustwidth}

\subsubsection{Kullback Leibler Divergence}
\begin{adjustwidth}{4em}{0pt}
\hspace{\parindent}Kullback Leibler Divergence merupakan salah satu teknik penghitungan divergensi dari distribusi dua nilai (pada umumnya distribusi probabilitas). Kullback Leibler Divergence pada distribusi data  P dan Q  didefinisikan sebagai berikut :
$D_{Kl}(P||Q) = \sum\limits_{i}P(i)ln\frac{P(i)}{Q(i)}$
dengan P(i) merupakan nilai tendensi dari data ke-i pada dataset-P dan Q(i) merupakan nilai tendensi dari data ke-i pada dataset-Q.

Pada kasus ini, KL Divergence digunakan untuk menghitung divergensi dari dua nilai estimated score yaitu estimasi probabilitas (persentase) profit dari suatu daerah pada cluster tertentu. Estimated score ini  yang akan menjadi attribute utama untuk membandingkan divergensi profit yang akan dianalisis.

\end{adjustwidth}

\subsection{Teknik}

\subsubsection{Preprocessing}

\begin{adjustwidth}{4em}{0pt}

\hspace{\parindent}Sebelum dataset diproses, perlu dilakukan langkah-langkah tertentu terlebih dahulu agar dataset tersebut lebih mudah untuk diproses dan sesuai dengan kriteria yang diinginkan.

\begin{itemize}
	\item{Data Filtering}
		
		Data filtering adalah proses pembuangan data-data yang tidak memenuhi batasan yang ditentukan. Pembuangan data yang tidak memenuhi batasan dilakukan agar hasil penilitian relevan dengan batasan tersebut dan proses evaluasi dan analisa data menjadi lebih mudah dan cepat karena tidak ada data sampah yang terlibat dalam komputasi-komputasi yang dilakukan.
		
	\item{Data Standardization}
		
		Standarisasi data termasuk mengatur kembali banyaknya baris atau kolom pada dataset dan mengubah nilai yang ada menjadi kisaran tertentu, misalnya data nominal dijadikan numerik, boolean, atau lainnya. Dalam penelitian ini, penulis melakukan standarisasi data, yaitu mengubah nilai-nilai numerik menjadi nilai probabilitasnya (persentase).
		
	\item{Feature Extraction}
		
		Feature extraction adalah pengurangan atribut pada dataset apabila ukuran dataset terlalu besar atau ada atribut yang berulang (redundant). Dalam penelitian ini, kami mengabaikan atribut call type, origin call, origin stand, dan taxi id, karena tidak relevan dengan tujuan analisa yang dilakukan.
		
\end{itemize}

\end{adjustwidth}

\subsubsection{Modeling}
\begin{adjustwidth}{4em}{0pt}
	
\hspace{\parindent}Setelah data melalui preprocessing, data akan dimodelkan untuk menggambarkan distribusi data tersebut dan hubungan antara data yang satu dengan yang lain. Pada penelitian ini, teknik modeling yang digunakan adalah clustering. yakni penggabungan data-data yang memiliki kemiripan tertentu dalam satu cluster (kelompok).

\end{adjustwidth}

\subsubsection{Inference}

\begin{adjustwidth}{4em}{0pt}
	
\hspace{\parindent}Inferensi atau penarikan kesimpulan dilakukan terhadap hasil modelling pada langkah kedua dengan menggunakan konsep-konsep statistik sehingga diperoleh informasi yang diinginkan.

\end{adjustwidth}

\section{Desain dan Implementasi}

\subsection{title}

\begin{tabular}{ | l | l | l | l | p{3cm} | }
	\hline
	Cluster ID & Number of Data & Centroid Latitude & Centroid Longitude & Region Name \\ \hline
	
	0 &	52570 &	41.1767 & -8.5408 &	Rua Doutor Raúl Chagas 77, 4435-124 Rio Tinto \\ \hline
	
	1 &
	3265 &
	40.909 &
	-8.5939 &
	Travessa da Estrada Nova 101, 3885-062 Arada \\ \hline
	
	2 &
	476 &
	41.129 &
	-7.592 &
	EM512 5, 5120 \\ \hline
	
	3 &
	171187 &
	41.1747 &
	-8.653 &
	Rua Conde Covilhã 1460, 4100 Porto \\ \hline
	
	4 &
	229332 &
	41.1826 &
	-8.6051 &
	Alameda Professor Hernâni Monteiro 813, 4200 Porto \\ \hline
	
	5 &
	705847 &
	41.1444 &
	-8.6145 &
	Travessa do Ferraz 2, 4050-141 Porto \\ \hline
	
	6 &
	2402 &
	41.341 &
	-8.3149 &
	CM1128 404, 4620 \\ \hline
	
	7 &
	453884 &
	41.1611 &
	-8.6275 &
	Avenida da França 352, 4050-278 Porto \\ \hline
	
	8 &
	287113 &
	41.155 &
	-8.6448 &
	IC23, 4150-172 Porto \\ \hline
	
	9 &
	476618 &
	41.1601 &
	-8.5832 &
	Rua José Monteiro da Costa, 4350-307 Porto \\ \hline
	
	10 &
	76135 &
	41.2426 &
	-8.6709 &
	Rua da Caralinda 259, 4470-558 Vila Nova da Telha \\ \hline
	
	11 &
	189885 &
	41.1576 &
	-8.6697 &
	Rua Afonso Baldaia 368, 4150-002 Porto \\ \hline
	
	12 &
	595941 &
	41.1528 &
	-8.6052 &
	Rua de Santa Catarina 753, 4000-425 Porto \\ \hline
	
	13 &
	80643 &
	41.1782 &
	-8.6877 &
	Rua Dom João i 394, 4450-163 Matosinhos \\ \hline
	
	14 &
	182 &
	39.2218 &
	-8.9714 &
	IC2, 2065 Alcoentre \\
	\hline
\end{tabular}

\end{document}
